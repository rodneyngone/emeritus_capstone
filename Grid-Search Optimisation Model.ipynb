{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e578d39-3087-4e18-aaaf-f4f9d592745a",
   "metadata": {},
   "source": [
    "# Optimisation on Logistic Regression using Grid Search\n",
    "\n",
    "In this repo, we use the HEBO package to perform Bayesian Optimisation Hyperparameter search. We will use this to try to find the optimal hyper-parameters for a Logistic Regression model to classify returns on Gold daily prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15b0fb-db3e-4226-8ef4-0ba2ca814ced",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "073b831f-a620-47c8-95f0-362d969d0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from hebo.optimizers.bo import BO\n",
    "from hebo.design_space.design_space import DesignSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba798bea-15f6-480c-b49b-cda1de43f11a",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "For this notebook, we will work with daily gold price historical data available on Kaggle: \n",
    "\n",
    "https://www.kaggle.com/datasets/psycon/daily-gold-price-historical-data\n",
    "\n",
    "The objective is to determine the next-day's forward return sign by training a model on past data. This is a straightforward supervised machine learning classification tast: given past data, we want to train a binary outcome on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e702df55-8b60-4301-b6e4-547f0b269ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>289.5</td>\n",
       "      <td>289.5</td>\n",
       "      <td>280.0</td>\n",
       "      <td>283.7</td>\n",
       "      <td>21621</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>283.7</td>\n",
       "      <td>285.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>282.1</td>\n",
       "      <td>25448</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>281.6</td>\n",
       "      <td>282.8</td>\n",
       "      <td>280.2</td>\n",
       "      <td>282.4</td>\n",
       "      <td>19055</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>282.5</td>\n",
       "      <td>284.5</td>\n",
       "      <td>282.0</td>\n",
       "      <td>282.9</td>\n",
       "      <td>11266</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>282.4</td>\n",
       "      <td>283.9</td>\n",
       "      <td>281.8</td>\n",
       "      <td>282.7</td>\n",
       "      <td>30603</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Open   High    Low  Close  Volume Currency\n",
       "0  2000-01-04  289.5  289.5  280.0  283.7   21621      USD\n",
       "1  2000-01-05  283.7  285.0  281.0  282.1   25448      USD\n",
       "2  2000-01-06  281.6  282.8  280.2  282.4   19055      USD\n",
       "3  2000-01-07  282.5  284.5  282.0  282.9   11266      USD\n",
       "4  2000-01-10  282.4  283.9  281.8  282.7   30603      USD"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in raw data\n",
    "df = pd.read_csv('data/gold.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecd3152d-23bf-4d26-9de8-13ac3b9c0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep dataframe\n",
    "df = df.set_index('Date').drop(columns='Currency')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "524afb5a-28d5-4198-83bb-9182a3242539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5703 entries, 2000-01-04 to 2022-09-02\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    5703 non-null   float64\n",
      " 1   high    5703 non-null   float64\n",
      " 2   low     5703 non-null   float64\n",
      " 3   close   5703 non-null   float64\n",
      " 4   volume  5703 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 267.3 KB\n"
     ]
    }
   ],
   "source": [
    "# look at dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff4ad299-7a2b-48cb-8cb6-190a7dc776cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total zeros in open column: 0\n",
      "Total zeros in high column: 0\n",
      "Total zeros in low column: 0\n",
      "Total zeros in close column: 0\n",
      "Total zeros in volume column: 10\n"
     ]
    }
   ],
   "source": [
    "# check for zeros, or outliers\n",
    "num = 0\n",
    "for i in df.columns:\n",
    "    zero_count = df[i][df[i]==0].count()\n",
    "    print(f'Total zeros in {i} column: {zero_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80ee6959-606b-4393-b55c-f31ced381db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop zero volume rows\n",
    "df = df[df.volume!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377aa46c-3881-41ce-a688-9333fd410759",
   "metadata": {},
   "source": [
    "### Convert non-stationary prices into stationary returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb7f1147-f717-430a-a944-376501ec5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X, y partitions\n",
    "X = (np.log(df/df.shift(1))).dropna()\n",
    "y = np.sign(np.log(df.close.shift(-1)/df.close).dropna())\n",
    "y.name = 'y'\n",
    "\n",
    "# remove zero ys\n",
    "y = y[y!=0]\n",
    "\n",
    "# join X,y\n",
    "train_df = pd.concat((X, y), axis=1, join='inner')\n",
    "# re-split\n",
    "y = train_df.y\n",
    "X = train_df.drop(columns='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31912137-ffce-4125-a466-ac75f2c24a67",
   "metadata": {},
   "source": [
    "### Distribution of Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb662453-6dd9-4879-8b09-623487895759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y, edgecolor='k');\n",
    "plt.xlabel('Label'); plt.ylabel('Count'); plt.title('Count of Labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d525f0-a24f-4c97-a0fd-426c66cd83cd",
   "metadata": {},
   "source": [
    "There is a small class imbalance here that will be accounted for when using the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60aa556-9cdc-441d-b47c-d022c498bb2e",
   "metadata": {},
   "source": [
    "### Separate into training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a21d56d-5b27-4c21-a4ac-635b7fbbbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumptions: 70% training, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efbb9ac-3035-4af8-a702-63899e1136ba",
   "metadata": {},
   "source": [
    "### Scale X training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fcab6594-ed4a-4959-88d0-13f8d313ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaling model\n",
    "sca_model = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97cdbb61-9d65-479e-a4aa-44fdc00fbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model to training data\n",
    "sca_model.fit(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e8486108-f7d0-45d3-85b4-256bc0207394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the raw data\n",
    "X_train = sca_model.transform(X_train)\n",
    "X_test = sca_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e0e9e-71ed-479c-a966-9ead1105bf2d",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4196049-31a5-45e7-b758-7db0781f29ca",
   "metadata": {},
   "source": [
    "We will use the SciKit-Learn implementation of the Logistic Regression model. Due to the small imbalance in our classes, we shall ensure our class weights are set to balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b1e890a3-00f5-46a4-8db3-1876225f4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model\n",
    "model = LogisticRegression(fit_intercept=True, class_weight='balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b53747-6594-42b8-adc1-9085d0c2953b",
   "metadata": {},
   "source": [
    "We shall set a wide range of parameters for the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eeb77dc5-7fd2-4688-8315-0ddcb14fc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters\n",
    "parameters = [{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "              {'penalty': ['none', 'elasticnet', 'l1', 'l2']},\n",
    "              {'C': [0.001, 0.01, 0.1, 1, 10, 100]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9d9e1-f19e-4b31-a0b9-6985dd3a3cb2",
   "metadata": {},
   "source": [
    "We shall implement SciKit-Learn's out of the box GridSearchCV implementation that also incorporates cross-validation within training with accuracy as our metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "05c85533-0e61-45fd-9585-66d030f3de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, scoring='accuracy', cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031ecf9-9622-4ccc-abf9-c20355013ee2",
   "metadata": {},
   "source": [
    "All we need to do is to fit the model on the training data and make predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac328385-cf21-43e4-97cd-4615c5f74ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] END ...................................solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...................................solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...................................solver=newton-cg; total time=   0.0s\n",
      "[CV] END .......................................solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......................................solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......................................solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................................solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................................solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................................solver=liblinear; total time=   0.0s\n",
      "[CV] END .........................................solver=sag; total time=   0.0s\n",
      "[CV] END .........................................solver=sag; total time=   0.0s\n",
      "[CV] END .........................................solver=sag; total time=   0.0s\n",
      "[CV] END ........................................solver=saga; total time=   0.0s\n",
      "[CV] END ........................................solver=saga; total time=   0.0s\n",
      "[CV] END ........................................solver=saga; total time=   0.0s\n",
      "[CV] END .......................................penalty=none; total time=   0.0s\n",
      "[CV] END .......................................penalty=none; total time=   0.0s\n",
      "[CV] END .......................................penalty=none; total time=   0.0s\n",
      "[CV] END .................................penalty=elasticnet; total time=   0.0s\n",
      "[CV] END .................................penalty=elasticnet; total time=   0.0s\n",
      "[CV] END .................................penalty=elasticnet; total time=   0.0s\n",
      "[CV] END .........................................penalty=l1; total time=   0.0s\n",
      "[CV] END .........................................penalty=l1; total time=   0.0s\n",
      "[CV] END .........................................penalty=l1; total time=   0.0s\n",
      "[CV] END .........................................penalty=l2; total time=   0.0s\n",
      "[CV] END .........................................penalty=l2; total time=   0.0s\n",
      "[CV] END .........................................penalty=l2; total time=   0.0s\n",
      "[CV] END ............................................C=0.001; total time=   0.0s\n",
      "[CV] END ............................................C=0.001; total time=   0.0s\n",
      "[CV] END ............................................C=0.001; total time=   0.0s\n",
      "[CV] END .............................................C=0.01; total time=   0.0s\n",
      "[CV] END .............................................C=0.01; total time=   0.0s\n",
      "[CV] END .............................................C=0.01; total time=   0.0s\n",
      "[CV] END ..............................................C=0.1; total time=   0.0s\n",
      "[CV] END ..............................................C=0.1; total time=   0.0s\n",
      "[CV] END ..............................................C=0.1; total time=   0.0s\n",
      "[CV] END ................................................C=1; total time=   0.0s\n",
      "[CV] END ................................................C=1; total time=   0.0s\n",
      "[CV] END ................................................C=1; total time=   0.0s\n",
      "[CV] END ...............................................C=10; total time=   0.0s\n",
      "[CV] END ...............................................C=10; total time=   0.0s\n",
      "[CV] END ...............................................C=10; total time=   0.0s\n",
      "[CV] END ..............................................C=100; total time=   0.0s\n",
      "[CV] END ..............................................C=100; total time=   0.0s\n",
      "[CV] END ..............................................C=100; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          random_state=42),\n",
       "             param_grid=[{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                     'saga']},\n",
       "                         {'penalty': ['none', 'elasticnet', 'l1', 'l2']},\n",
       "                         {'C': [0.001, 0.01, 0.1, 1, 10, 100]}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a5f96121-de45-43cf-8d4a-3b38c8f8d39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 0.01}\n",
      "in-sample accuracy : 0.5293694643886084\n",
      "out-of-sample accuracy : 0.5200708382526564\n"
     ]
    }
   ],
   "source": [
    "test_predictions = grid_search.predict(X_test)\n",
    "out_sample_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",grid_search.best_params_)\n",
    "print(\"in-sample accuracy :\",grid_search.best_score_)\n",
    "print(\"out-of-sample accuracy :\", out_sample_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73edd5c4-7c98-44b8-9d13-6d742392040c",
   "metadata": {},
   "source": [
    "The results are encouraging for financial data but given the small size of the dataset, in order to improve performance, it probably makes sense to gather more data and create additional features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fml",
   "language": "python",
   "name": "fml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
